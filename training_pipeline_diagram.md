# Training Pipeline Diagram for Qwen Indonesian Food Recipe Model

```mermaid
flowchart TD
    A[ğŸš€ Initialize Training Process] --> B[ğŸ”§ Setup Environment & Imports]
    B --> C{ğŸ“‚ Check for Existing Checkpoints}
    
    C -->|Checkpoints Found| D[ğŸ“¥ Load Model from Latest Checkpoint]
    C -->|No Checkpoints| E[ğŸ¤— Load Base Qwen Model from HuggingFace]
    
    D --> F[ğŸ“¥ Load Tokenizer from Checkpoint]
    E --> G[ğŸ¤— Load Base Tokenizer from HuggingFace]
    
    F --> H[âš™ï¸ Configure Model Settings]
    G --> H
    
    H --> I[ğŸ› ï¸ Set Pad Token ID]
    I --> J[ğŸ”§ Prepare Model for k-bit Training]
    J --> K[ğŸ“‹ Setup Base Model Config]
    K --> L[ğŸ“ Create Output Directory]
    
    L --> M[ğŸ¯ Configure LoRA Parameters]
    M --> N[ğŸ”— Apply LoRA Adapters to Model]
    N --> O[âš¡ Enable Input Gradients]
    
    O --> P[ğŸ“Š Load Recipe Dataset CSV]
    P --> Q{ğŸ“‹ Validate Dataset Exists}
    Q -->|File Not Found| R[âŒ Raise FileNotFoundError]
    Q -->|File Found| S[ğŸ” Analyze Dataset Structure]
    
    S --> T[ğŸ§¹ Clean Ingredients Data]
    T --> U[ğŸ”„ Generate Multiple Training Examples]
    
    U --> V[ğŸ“ Create Standard Recipe Requests]
    U --> W[â“ Create Simple Recipe Questions]  
    U --> X[ğŸ¥˜ Create Ingredient-based Recommendations]
    U --> Y[ğŸ” Create Ingredient Inquiry Responses]
    
    V --> Z[ğŸ’¬ Apply Chat Templates]
    W --> Z
    X --> Z
    Y --> Z
    
    Z --> AA[ğŸ¯ Tokenize All Examples]
    AA --> BB[ğŸ“¦ Create Data Collator for LM]
    
    BB --> CC[âš™ï¸ Setup Training Arguments]
    CC --> DD[ğŸ“Š Configure TensorBoard Logging]
    DD --> EE[ğŸ‹ï¸ Initialize Trainer Object]
    
    EE --> FF[ğŸ”„ Start Training Loop]
    FF --> GG{ğŸ¯ Training Successful?}
    
    GG -->|Success| HH[ğŸ’¾ Save Fine-tuned Model]
    GG -->|Failed| II[ğŸš¨ Handle Training Error]
    
    HH --> JJ[ğŸ’¾ Save Tokenizer]
    JJ --> KK[ğŸ“Š Save Training Metadata]
    KK --> LL[ğŸ“ˆ Close TensorBoard Writer]
    LL --> MM[âœ… Training Complete Successfully]
    
    II --> NN[âŒ Raise Exception & Stop]
    
    subgraph "ğŸ¯ LoRA Configuration Details"
        M1[ğŸ“ Rank: 16]
        M2[ğŸ”¢ Alpha: 32]
        M3[ğŸ¯ Target Modules:<br/>q_proj, v_proj, k_proj,<br/>o_proj, gate_proj,<br/>up_proj, down_proj]
        M4[ğŸ“‰ Dropout: 0.05]
        M5[ğŸš« Bias: none]
        M --> M1
        M --> M2
        M --> M3
        M --> M4
        M --> M5
    end
    
    subgraph "ğŸ“Š Dataset Processing Details"
        T1[ğŸ§¹ Split Ingredients by '--']
        T2[ğŸ”¤ Remove Numbers & Measurements]
        T3[ğŸ“ Extract Main Ingredient Names]
        T4[ğŸ”¤ Convert to Lowercase]
        T --> T1
        T1 --> T2
        T2 --> T3
        T3 --> T4
    end
    
    subgraph "ğŸ”„ Training Example Generation"
        U1[ğŸ“ 5 Standard Recipe Variations]
        U2[â“ 15 Simple Question Variations]
        U3[ğŸ¥˜ 10 Ingredient Recommendation Variations]
        U4[ğŸ” 10 Ingredient Inquiry Variations]
        U --> U1
        U --> U2
        U --> U3
        U --> U4
    end
    
    subgraph "âš™ï¸ Training Configuration"
        CC1[ğŸ”„ Epochs: 3]
        CC2[ğŸ“¦ Batch Size: 2]
        CC3[ğŸ“ˆ Learning Rate: 2e-5]
        CC4[ğŸ” Gradient Accumulation: 4]
        CC5[ğŸ’¾ Save Steps: 500]
        CC6[ğŸ“Š Logging Steps: 100]
        CC7[âš–ï¸ Weight Decay: 0.01]
        CC8[ğŸ”¥ FP16: True (if CUDA)]
        CC9[âœ‚ï¸ Gradient Checkpointing: True]
        CC10[ğŸ¯ Label Smoothing: 0.1]
        CC11[ğŸ”¥ Warmup Steps: 100]
        CC --> CC1
        CC --> CC2
        CC --> CC3
        CC --> CC4
        CC --> CC5
        CC --> CC6
        CC --> CC7
        CC --> CC8
        CC --> CC9
        CC --> CC10
        CC --> CC11
    end
    
    subgraph "ğŸ’¾ Output & Monitoring"
        KK1[ğŸ“Š Model Name & Version]
        KK2[ğŸ“ˆ Total Recipes Count]
        KK3[ğŸ”¢ Total Training Examples]
        KK4[âœ¨ Model Capabilities List]
        KK5[ğŸ“Š TensorBoard Logs]
        KK6[ğŸ’¾ Checkpoint Management]
        KK --> KK1
        KK --> KK2
        KK --> KK3
        KK --> KK4
        KK --> KK5
        KK --> KK6
    end
    
    style A fill:#e3f2fd
    style MM fill:#c8e6c9
    style NN fill:#ffcdd2
    style R fill:#ffcdd2
    style FF fill:#fff3e0
    style HH fill:#f3e5f5
    style GG fill:#ffecb3
    style C fill:#e8f5e8
    style Q fill:#e8f5e8
```

## ğŸ” Detailed Pipeline Components

### 1. ğŸš€ **Initialization & Setup**
- Import semua library yang diperlukan (torch, transformers, pandas, datasets, peft)
- Setup environment variables dan device detection (CUDA/CPU)
- Initialize TensorBoard writer untuk monitoring

### 2. ğŸ“‚ **Model Loading Strategy**
- **Checkpoint Detection**: Scan output directory untuk checkpoint terbaru
- **Resume Logic**: Load dari checkpoint jika ada, otherwise load base model
- **Model Variants**: Support untuk Qwen 0.5B, 1.5B, atau 3B
- **Device Mapping**: Automatic device mapping untuk multi-GPU

### 3. ğŸ¯ **LoRA Configuration (Parameter Efficient Fine-tuning)**
- **Rank 16**: Balance antara performance dan efisiensi
- **Alpha 32**: Scaling factor untuk LoRA weights
- **Target Modules**: All attention & MLP layers
- **Task Type**: Causal Language Modeling
- **Dropout**: 0.05 untuk regularization

### 4. ğŸ“Š **Advanced Data Processing**
- **CSV Validation**: Check file existence dan structure
- **Ingredient Cleaning**: Remove measurements, extract main ingredients
- **Multi-variation Generation**: 40+ variations per recipe
- **Chat Template Formatting**: Apply Qwen chat format
- **Tokenization**: Max length 512 tokens dengan padding

### 5. ğŸ”„ **Training Example Types**
- **Standard Requests** (5 variations): Formal recipe requests
- **Simple Questions** (15 variations): Casual recipe inquiries  
- **Ingredient Recommendations** (10 variations): Suggest dishes from available ingredients
- **Ingredient Inquiries** (10 variations): What to cook with specific ingredients

### 6. âš™ï¸ **Comprehensive Training Configuration**
- **Memory Optimization**: FP16, gradient checkpointing, gradient accumulation
- **Learning Schedule**: Warmup steps, weight decay, label smoothing
- **Monitoring**: TensorBoard integration, detailed logging
- **Checkpointing**: Save every 500 steps, keep only 2 latest
- **Resume Capability**: Automatic resume from latest checkpoint

### 7. ğŸ’¾ **Output Management**
- **Model Artifacts**: Fine-tuned model, tokenizer, configuration
- **Metadata**: Training statistics, model capabilities
- **Monitoring**: TensorBoard logs, training curves
- **Backup**: Checkpoint management dengan rotation

### 8. ğŸ”„ **Error Handling & Recovery**
- **File Validation**: Check dataset availability  
- **Training Monitoring**: Success/failure detection
- **Exception Handling**: Graceful error management
- **Resume Logic**: Continue from interruption points

## ğŸ“ˆ **Model Capabilities After Training**
1. ğŸ½ï¸ Memberikan resep lengkap masakan Indonesia
2. â“ Menjawab pertanyaan sederhana tentang resep
3. ğŸ¥˜ Merekomendasikan masakan berdasarkan bahan tersedia
4. ğŸ” Memberikan saran penggunaan bahan tertentu
5. ğŸ’¡ Tips dan trik memasak tradisional Indonesia 